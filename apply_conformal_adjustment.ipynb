{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6330465",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from conformal_utils import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7601a43",
   "metadata": {},
   "source": [
    "Run this notebook after running `get_posterior_quantiles_oracle.{ipynb, py}`\n",
    "\n",
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e100fd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data \n",
    "softmax_scores = torch.load('/home/eecs/tiffany_ding/code/SimCLRv2-Pytorch/.cache/logits/imagenet_train_subset_softmax.pt', map_location=torch.device('cpu'))\n",
    "softmax_scores = softmax_scores.numpy()\n",
    "labels = torch.load('/home/eecs/tiffany_ding/code/SimCLRv2-Pytorch/.cache/logits/imagenet_train_subset_labels.pt', map_location=torch.device('cpu'))\n",
    "labels = labels.type(torch.LongTensor).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "656b527e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = 1 - softmax_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "572b0dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 224 ms, sys: 110 ms, total: 333 ms\n",
      "Wall time: 331 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "n = 20 # Number of points per class k used to fit Beta distributions\n",
    "n_tune = 10 # Number of points per class k used to perform conformal adjustment \n",
    "num_classes = 1000\n",
    "\n",
    "# Split into calibration and validation datasets, then further break down calibration set\n",
    "# calib_scores, calib_labels, _, _ = split_X_and_y(scores, labels, n + n_tune, num_classes=1000, seed=0)\n",
    "_,_, scores2, labels2 = split_X_and_y(calib_scores, calib_labels, n, num_classes=1000, seed=0)\n",
    "\n",
    "# FOR TESTING PURPOSES\n",
    "# Optionally, further restrict calibration set to only include a single datapoint per class\n",
    "scores2, labels2, _, _ = split_X_and_y(scores2, labels2, 1, num_classes=1000, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "387135f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get split of data not used for calibration\n",
    "# _, _, unused_scores, unused_labels = split_X_and_y(scores, labels, 20, num_classes=1000, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e51773dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split unused data into \n",
    "# # 1. Data for estimating conformal adjustment and\n",
    "# # 2. Data for computing coverage\n",
    "\n",
    "# # Select 10 examples per class (10,000 total examples) for 1. and leave the rest for 2. \n",
    "# scores1, labels1, scores2, labels2 = split_X_and_y(unused_scores, unused_labels, 10, num_classes=1000, seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bcded7",
   "metadata": {},
   "source": [
    "### Method 1: Adjust which quantile we take of the posterior distr.\n",
    "\n",
    "We want to find $\\tilde{\\alpha}$ such that the $(1-\\tilde{\\alpha})\\%$-quantile of the posterior score distribution achieves marginal coverage of $1-\\alpha$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ded86d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_samples = np.load('.cache/cached_samples_06-10-22.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad9fcf5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current quantile guess: 0.9000\n",
      "Marginal coverage: 0.9070\n",
      "Search range: [0.85, 0.9]\n",
      "\n",
      "Current quantile guess: 0.8750\n",
      "Marginal coverage: 0.8840\n",
      "Search range: [0.875, 0.9]\n",
      "\n",
      "Current quantile guess: 0.8875\n",
      "Marginal coverage: 0.8950\n",
      "Search range: [0.8875, 0.9]\n",
      "\n",
      "Current quantile guess: 0.8938\n",
      "Marginal coverage: 0.8980\n",
      "Search range: [0.89375, 0.9]\n",
      "\n",
      "Current quantile guess: 0.8969\n",
      "Marginal coverage: 0.9010\n",
      "Search range: [0.89375, 0.8968750000000001]\n",
      "\n",
      "Current quantile guess: 0.8953\n",
      "Marginal coverage: 0.9010\n",
      "Search range: [0.89375, 0.8953125000000001]\n",
      "\n",
      "Current quantile guess: 0.8945\n",
      "Marginal coverage: 0.9000\n",
      "Search range: [0.89453125, 0.8953125000000001]\n",
      "\n",
      "FINAL QUANTILE: 0.89453125\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.1\n",
    "num_classes = 1000\n",
    "\n",
    "# Restrict search between (1 - alpha) +/- 0.5 to start\n",
    "quantile_min = (1 - alpha) - .05\n",
    "quantile_max = (1 - alpha) + .05\n",
    "\n",
    "# ===== Perform binary search =====\n",
    "# Convergence criteria: Either (1) marginal coverage is within tol of desired or (2)\n",
    "# quantile_min and quantile_max differ by less than .001, so there is no need to try \n",
    "# to get a more precise estimate\n",
    "tol = 0.0005\n",
    "\n",
    "marginal_coverage = 0\n",
    "while np.abs(marginal_coverage - (1-alpha)) > tol:\n",
    "    \n",
    "    quantile_guess = (quantile_min +  quantile_max) / 2\n",
    "    print(f\"\\nCurrent quantile guess: {quantile_guess:.4f}\")\n",
    "    \n",
    "    # 1. Get qhats_k\n",
    "    qhats = [np.quantile(cached_samples[k,:], quantile_guess, interpolation='higher') for k in range(num_classes)]\n",
    "    \n",
    "    # 2. Compute coverage using these qhats\n",
    "    preds = create_cb_prediction_sets(scores2, qhats)\n",
    "    marginal_coverage = compute_coverage(labels2, preds)\n",
    "    print(f\"Marginal coverage: {marginal_coverage:.4f}\")\n",
    "    \n",
    "    if marginal_coverage > 1 - alpha:\n",
    "        quantile_max = quantile_guess\n",
    "    else:\n",
    "        quantile_min = quantile_guess\n",
    "    print(f\"Search range: [{quantile_min}, {quantile_max}]\")\n",
    "        \n",
    "    if quantile_max - quantile_min < .0001:\n",
    "        quantile_guess = quantile_max # Conservative estimate, which ensures coverage\n",
    "        print(\"Adequate precision reached; stopping early.\")\n",
    "        break\n",
    "\n",
    "print(\"\\nFINAL QUANTILE:\", quantile_guess)\n",
    "\n",
    "# Using n=1 datapoints per class:\n",
    "#    FINAL QUANTILE: 0.89453125\n",
    "\n",
    "# Using n=10 datapoints per class:\n",
    "#   FINAL QUANTILE: 0.88828"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c38488",
   "metadata": {},
   "source": [
    "#### Save qhats obtained by getting the `quantile_guess` quantile of the posterior score distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99071476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the 89.453% quantile of the posterior score distribution...\n",
      "Saved conformalized qhats to .cache/conformalized_qhats.npy\n"
     ]
    }
   ],
   "source": [
    "print(f'Computing the {quantile_guess * 100:.3f}% quantile of the posterior score distribution...')\n",
    "conformalized_qhats = [np.quantile(cached_samples[k,:], quantile_guess, interpolation='higher') for k in range(num_classes)]\n",
    "\n",
    "\n",
    "save_to = '.cache/conformalized_qhats.npy'\n",
    "np.save(save_to, conformalized_qhats)\n",
    "print(f'Saved conformalized qhats to {save_to}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91383f07",
   "metadata": {},
   "source": [
    "### Method 2: Apply additive (or multiplicative) offset to $\\widehat{q}^{EB}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "211cf7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
